{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import math\n",
    "\n",
    "class FloatingPointExplainer:\n",
    "    \"\"\"Explain exponent and mantissa in floating point representation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"FLOATING POINT REPRESENTATION: EXPONENT & MANTISSA\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"Floating point numbers use scientific notation in binary:\")\n",
    "        print(\"Number = Sign × Mantissa × 2^Exponent\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def explain_scientific_notation(self):\n",
    "        \"\"\"Start with familiar decimal scientific notation\"\"\"\n",
    "        print(\"\\n1. SCIENTIFIC NOTATION (Decimal)\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        examples = [\n",
    "            (1234.5, \"1.2345 × 10^3\"),\n",
    "            (0.00789, \"7.89 × 10^-3\"),\n",
    "            (0.5, \"5.0 × 10^-1\"),\n",
    "            (8.0, \"8.0 × 10^0\")\n",
    "        ]\n",
    "        \n",
    "        for number, notation in examples:\n",
    "            print(f\"{number:>8} = {notation}\")\n",
    "            # Break down the components\n",
    "            if number != 0:\n",
    "                # Find the exponent (power of 10)\n",
    "                exponent = math.floor(math.log10(abs(number)))\n",
    "                # Find the mantissa (significant digits)\n",
    "                mantissa = number / (10 ** exponent)\n",
    "                print(f\"         Mantissa: {mantissa:.4f}, Exponent: {exponent}\")\n",
    "        \n",
    "        print(\"\\nIn scientific notation:\")\n",
    "        print(\"- MANTISSA: The significant digits (1.2345, 7.89, etc.)\")\n",
    "        print(\"- EXPONENT: The power of 10 (3, -3, -1, 0)\")\n",
    "    \n",
    "    def explain_binary_scientific_notation(self):\n",
    "        \"\"\"Explain binary scientific notation\"\"\"\n",
    "        print(\"\\n2. BINARY SCIENTIFIC NOTATION\")\n",
    "        print(\"-\" * 40)\n",
    "        print(\"Floating point uses base-2 (binary) scientific notation:\")\n",
    "        print(\"Number = Mantissa × 2^Exponent\")\n",
    "        \n",
    "        examples = [\n",
    "            (5.0, \"101.0\", \"1.01 × 2^2\"),\n",
    "            (2.5, \"10.1\", \"1.01 × 2^1\"),\n",
    "            (1.25, \"1.01\", \"1.01 × 2^0\"),\n",
    "            (0.625, \"0.101\", \"1.01 × 2^-1\")\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n{'Decimal':<8} {'Binary':<10} {'Scientific':<15} {'Components'}\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        for decimal, binary, scientific, in examples:\n",
    "            # Calculate actual components\n",
    "            if decimal != 0:\n",
    "                # Find position of first 1 bit\n",
    "                binary_str = bin(int(decimal * 16))[2:]  # Scale up to see fractional part\n",
    "                # This is simplified - real calculation is more complex\n",
    "                mantissa_part = scientific.split(' × ')[0]\n",
    "                exponent_part = scientific.split('^')[1]\n",
    "                print(f\"{decimal:<8} {binary:<10} {scientific:<15} M:{mantissa_part}, E:{exponent_part}\")\n",
    "    \n",
    "    def demonstrate_ieee754_format(self):\n",
    "        \"\"\"Demonstrate IEEE 754 format breakdown\"\"\"\n",
    "        print(\"\\n3. IEEE 754 FLOATING POINT FORMAT\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        print(\"32-bit Float (FP32) structure:\")\n",
    "        print(\"┌─┬────────┬───────────────────────┐\")\n",
    "        print(\"│S│EEEEEEEE│MMMMMMMMMMMMMMMMMMMMMMM│\")\n",
    "        print(\"│1│   8    │          23           │\")\n",
    "        print(\"└─┴────────┴───────────────────────┘\")\n",
    "        print(\" Sign  Exp    Mantissa\")\n",
    "        \n",
    "        # Analyze specific number\n",
    "        test_value = 12.375\n",
    "        print(f\"\\nAnalyzing: {test_value}\")\n",
    "        \n",
    "        # Get binary representation\n",
    "        packed = struct.pack('>f', test_value)\n",
    "        bits = struct.unpack('>I', packed)[0]\n",
    "        binary = format(bits, '032b')\n",
    "        \n",
    "        # Extract components\n",
    "        sign_bit = binary[0]\n",
    "        exponent_bits = binary[1:9]\n",
    "        mantissa_bits = binary[9:]\n",
    "        \n",
    "        print(f\"Binary:    {binary}\")\n",
    "        print(f\"Sign:      {sign_bit} ({'positive' if sign_bit == '0' else 'negative'})\")\n",
    "        print(f\"Exponent:  {exponent_bits} (binary) = {int(exponent_bits, 2)} (decimal)\")\n",
    "        print(f\"Mantissa:  {mantissa_bits}\")\n",
    "        \n",
    "        # Explain the calculation\n",
    "        print(f\"\\nStep-by-step calculation:\")\n",
    "        print(f\"1. Sign: (-1)^{sign_bit} = {(-1)**int(sign_bit)}\")\n",
    "        \n",
    "        exponent_value = int(exponent_bits, 2) - 127  # Remove bias\n",
    "        print(f\"2. Exponent: {int(exponent_bits, 2)} - 127 (bias) = {exponent_value}\")\n",
    "        \n",
    "        # Mantissa calculation (normalized form)\n",
    "        mantissa_value = 1.0  # Implicit leading 1\n",
    "        for i, bit in enumerate(mantissa_bits):\n",
    "            if bit == '1':\n",
    "                fraction_value = 1.0 / (2 ** (i + 1))\n",
    "                mantissa_value += fraction_value\n",
    "                print(f\"   Bit {i}: 1/(2^{i+1}) = {fraction_value}\")\n",
    "        \n",
    "        print(f\"3. Mantissa: 1 + fractional_part = {mantissa_value}\")\n",
    "        \n",
    "        final_value = (-1)**int(sign_bit) * mantissa_value * (2 ** exponent_value)\n",
    "        print(f\"4. Result: {(-1)**int(sign_bit)} × {mantissa_value} × 2^{exponent_value} = {final_value}\")\n",
    "    \n",
    "    def explain_mantissa_precision(self):\n",
    "        \"\"\"Explain how mantissa determines precision\"\"\"\n",
    "        print(\"\\n4. MANTISSA AND PRECISION\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        print(\"The mantissa determines the PRECISION of the number:\")\n",
    "        print(\"- More mantissa bits = higher precision\")\n",
    "        print(\"- FP32: 23 mantissa bits ≈ 7 decimal digits precision\")\n",
    "        print(\"- FP16: 10 mantissa bits ≈ 3 decimal digits precision\")\n",
    "        print(\"- BF16: 7 mantissa bits ≈ 2 decimal digits precision\")\n",
    "        \n",
    "        # Demonstrate precision limits\n",
    "        print(f\"\\nPrecision demonstration:\")\n",
    "        \n",
    "        # Show what happens when we exceed precision\n",
    "        base = 1.0\n",
    "        increments = [1e-6, 1e-7, 1e-8, 1e-9]\n",
    "        \n",
    "        print(f\"Starting with: {base}\")\n",
    "        print(\"Adding small increments:\")\n",
    "        \n",
    "        for inc in increments:\n",
    "            result = base + inc\n",
    "            if result == base:\n",
    "                print(f\"  + {inc}: {result} (LOST PRECISION - too small to represent)\")\n",
    "            else:\n",
    "                print(f\"  + {inc}: {result}\")\n",
    "    \n",
    "    def explain_exponent_range(self):\n",
    "        \"\"\"Explain how exponent determines range\"\"\"\n",
    "        print(\"\\n5. EXPONENT AND RANGE\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        print(\"The exponent determines the RANGE of representable numbers:\")\n",
    "        print(\"- More exponent bits = wider range\")\n",
    "        print(\"- FP32: 8 exponent bits → range ~10^-38 to 10^38\")\n",
    "        print(\"- FP16: 5 exponent bits → range ~10^-4 to 10^4\") \n",
    "        print(\"- BF16: 8 exponent bits → same range as FP32\")\n",
    "        \n",
    "        formats = {\n",
    "            'FP32': {'exp_bits': 8, 'bias': 127},\n",
    "            'FP16': {'exp_bits': 5, 'bias': 15},\n",
    "            'BF16': {'exp_bits': 8, 'bias': 127}\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nRange comparison:\")\n",
    "        print(f\"{'Format':<6} {'Min Exp':<8} {'Max Exp':<8} {'Min Value':<12} {'Max Value'}\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        for fmt, props in formats.items():\n",
    "            max_exp_encoded = (2 ** props['exp_bits']) - 2  # Reserve 255 for special values\n",
    "            max_exp = max_exp_encoded - props['bias']\n",
    "            min_exp = 1 - props['bias']  # Minimum normalized exponent\n",
    "            \n",
    "            min_val = 2 ** min_exp\n",
    "            max_val = (2 - 2**(-23 if fmt == 'FP32' else -10 if fmt == 'FP16' else -7)) * (2 ** max_exp)\n",
    "            \n",
    "            print(f\"{fmt:<6} {min_exp:<8} {max_exp:<8} {min_val:<12.2e} {max_val:.2e}\")\n",
    "    \n",
    "    def demonstrate_special_cases(self):\n",
    "        \"\"\"Demonstrate special cases in floating point\"\"\"\n",
    "        print(\"\\n6. SPECIAL CASES\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        print(\"Special exponent values have special meanings:\")\n",
    "        print(\"\\nFor FP32 (8-bit exponent):\")\n",
    "        print(\"- Exponent = 0 (00000000): Zero or subnormal numbers\")\n",
    "        print(\"- Exponent = 255 (11111111): Infinity or NaN\")\n",
    "        print(\"- Exponent = 1-254: Normal numbers\")\n",
    "        \n",
    "        # Demonstrate special values\n",
    "        special_values = [\n",
    "            (0.0, \"Zero\"),\n",
    "            (float('inf'), \"Positive Infinity\"),\n",
    "            (float('-inf'), \"Negative Infinity\"),\n",
    "            (float('nan'), \"Not a Number (NaN)\")\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nSpecial value representations:\")\n",
    "        for value, description in special_values:\n",
    "            if not math.isnan(value):\n",
    "                packed = struct.pack('>f', value)\n",
    "                bits = struct.unpack('>I', packed)[0]\n",
    "                binary = format(bits, '032b')\n",
    "                sign = binary[0]\n",
    "                exponent = binary[1:9]\n",
    "                mantissa = binary[9:]\n",
    "                print(f\"{description:<20}: S={sign} E={exponent} M={mantissa[:10]}...\")\n",
    "    \n",
    "    def practical_implications(self):\n",
    "        \"\"\"Explain practical implications\"\"\"\n",
    "        print(\"\\n7. PRACTICAL IMPLICATIONS\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        print(\"Understanding exponent and mantissa helps explain:\")\n",
    "        \n",
    "        print(\"\\nA. Why 0.1 + 0.2 ≠ 0.3 in floating point:\")\n",
    "        a, b = 0.1, 0.2\n",
    "        result = a + b\n",
    "        print(f\"   {a} + {b} = {result}\")\n",
    "        print(f\"   Expected: 0.3\")\n",
    "        print(f\"   Difference: {abs(result - 0.3):.2e}\")\n",
    "        print(\"   → Some decimals cannot be exactly represented in binary\")\n",
    "        \n",
    "        print(\"\\nB. Precision loss in large numbers:\")\n",
    "        large_num = 16777216.0  # 2^24\n",
    "        incremented = large_num + 1.0\n",
    "        print(f\"   {large_num} + 1 = {incremented}\")\n",
    "        print(f\"   Lost precision: {incremented == large_num}\")\n",
    "        print(\"   → Mantissa can't represent small changes to large numbers\")\n",
    "        \n",
    "        print(\"\\nC. Why BF16 is better than FP16 for ML:\")\n",
    "        print(\"   - BF16: Same exponent range as FP32 (wide range)\")\n",
    "        print(\"   - FP16: Smaller exponent range (limited range)\")\n",
    "        print(\"   - ML models often have gradients across wide value ranges\")\n",
    "\n",
    "# Run the explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOATING POINT REPRESENTATION: EXPONENT & MANTISSA\n",
      "============================================================\n",
      "Floating point numbers use scientific notation in binary:\n",
      "Number = Sign × Mantissa × 2^Exponent\n",
      "============================================================\n",
      "\n",
      "1. SCIENTIFIC NOTATION (Decimal)\n",
      "----------------------------------------\n",
      "  1234.5 = 1.2345 × 10^3\n",
      "         Mantissa: 1.2345, Exponent: 3\n",
      " 0.00789 = 7.89 × 10^-3\n",
      "         Mantissa: 7.8900, Exponent: -3\n",
      "     0.5 = 5.0 × 10^-1\n",
      "         Mantissa: 5.0000, Exponent: -1\n",
      "     8.0 = 8.0 × 10^0\n",
      "         Mantissa: 8.0000, Exponent: 0\n",
      "\n",
      "In scientific notation:\n",
      "- MANTISSA: The significant digits (1.2345, 7.89, etc.)\n",
      "- EXPONENT: The power of 10 (3, -3, -1, 0)\n"
     ]
    }
   ],
   "source": [
    "explainer = FloatingPointExplainer()\n",
    "explainer.explain_scientific_notation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. BINARY SCIENTIFIC NOTATION\n",
      "----------------------------------------\n",
      "Floating point uses base-2 (binary) scientific notation:\n",
      "Number = Mantissa × 2^Exponent\n",
      "\n",
      "Decimal  Binary     Scientific      Components\n",
      "-------------------------------------------------------\n",
      "5.0      101.0      1.01 × 2^2      M:1.01, E:2\n",
      "2.5      10.1       1.01 × 2^1      M:1.01, E:1\n",
      "1.25     1.01       1.01 × 2^0      M:1.01, E:0\n",
      "0.625    0.101      1.01 × 2^-1     M:1.01, E:-1\n"
     ]
    }
   ],
   "source": [
    "explainer.explain_binary_scientific_notation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. IEEE 754 FLOATING POINT FORMAT\n",
      "----------------------------------------\n",
      "32-bit Float (FP32) structure:\n",
      "┌─┬────────┬───────────────────────┐\n",
      "│S│EEEEEEEE│MMMMMMMMMMMMMMMMMMMMMMM│\n",
      "│1│   8    │          23           │\n",
      "└─┴────────┴───────────────────────┘\n",
      " Sign  Exp    Mantissa\n",
      "\n",
      "Analyzing: 12.375\n",
      "Binary:    01000001010001100000000000000000\n",
      "Sign:      0 (positive)\n",
      "Exponent:  10000010 (binary) = 130 (decimal)\n",
      "Mantissa:  10001100000000000000000\n",
      "\n",
      "Step-by-step calculation:\n",
      "1. Sign: (-1)^0 = 1\n",
      "2. Exponent: 130 - 127 (bias) = 3\n",
      "   Bit 0: 1/(2^1) = 0.5\n",
      "   Bit 4: 1/(2^5) = 0.03125\n",
      "   Bit 5: 1/(2^6) = 0.015625\n",
      "3. Mantissa: 1 + fractional_part = 1.546875\n",
      "4. Result: 1 × 1.546875 × 2^3 = 12.375\n"
     ]
    }
   ],
   "source": [
    "explainer.demonstrate_ieee754_format()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. MANTISSA AND PRECISION\n",
      "----------------------------------------\n",
      "The mantissa determines the PRECISION of the number:\n",
      "- More mantissa bits = higher precision\n",
      "- FP32: 23 mantissa bits ≈ 7 decimal digits precision\n",
      "- FP16: 10 mantissa bits ≈ 3 decimal digits precision\n",
      "- BF16: 7 mantissa bits ≈ 2 decimal digits precision\n",
      "\n",
      "Precision demonstration:\n",
      "Starting with: 1.0\n",
      "Adding small increments:\n",
      "  + 1e-06: 1.000001\n",
      "  + 1e-07: 1.0000001\n",
      "  + 1e-08: 1.00000001\n",
      "  + 1e-09: 1.000000001\n"
     ]
    }
   ],
   "source": [
    "explainer.explain_mantissa_precision()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. EXPONENT AND RANGE\n",
      "----------------------------------------\n",
      "The exponent determines the RANGE of representable numbers:\n",
      "- More exponent bits = wider range\n",
      "- FP32: 8 exponent bits → range ~10^-38 to 10^38\n",
      "- FP16: 5 exponent bits → range ~10^-4 to 10^4\n",
      "- BF16: 8 exponent bits → same range as FP32\n",
      "\n",
      "Range comparison:\n",
      "Format Min Exp  Max Exp  Min Value    Max Value\n",
      "-------------------------------------------------------\n",
      "FP32   -126     127      1.18e-38     3.40e+38\n",
      "FP16   -14      15       6.10e-05     6.55e+04\n",
      "BF16   -126     127      1.18e-38     3.39e+38\n"
     ]
    }
   ],
   "source": [
    "explainer.explain_exponent_range()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. SPECIAL CASES\n",
      "----------------------------------------\n",
      "Special exponent values have special meanings:\n",
      "\n",
      "For FP32 (8-bit exponent):\n",
      "- Exponent = 0 (00000000): Zero or subnormal numbers\n",
      "- Exponent = 255 (11111111): Infinity or NaN\n",
      "- Exponent = 1-254: Normal numbers\n",
      "\n",
      "Special value representations:\n",
      "Zero                : S=0 E=00000000 M=0000000000...\n",
      "Positive Infinity   : S=0 E=11111111 M=0000000000...\n",
      "Negative Infinity   : S=1 E=11111111 M=0000000000...\n"
     ]
    }
   ],
   "source": [
    "explainer.demonstrate_special_cases()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. PRACTICAL IMPLICATIONS\n",
      "----------------------------------------\n",
      "Understanding exponent and mantissa helps explain:\n",
      "\n",
      "A. Why 0.1 + 0.2 ≠ 0.3 in floating point:\n",
      "   0.1 + 0.2 = 0.30000000000000004\n",
      "   Expected: 0.3\n",
      "   Difference: 5.55e-17\n",
      "   → Some decimals cannot be exactly represented in binary\n",
      "\n",
      "B. Precision loss in large numbers:\n",
      "   16777216.0 + 1 = 16777217.0\n",
      "   Lost precision: False\n",
      "   → Mantissa can't represent small changes to large numbers\n",
      "\n",
      "C. Why BF16 is better than FP16 for ML:\n",
      "   - BF16: Same exponent range as FP32 (wide range)\n",
      "   - FP16: Smaller exponent range (limited range)\n",
      "   - ML models often have gradients across wide value ranges\n"
     ]
    }
   ],
   "source": [
    "explainer.practical_implications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
